{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# AIT Development notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## notebook of structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "| #  | Name                                               | cells | for_dev | edit               | description                                                                |\n",
    "|----|----------------------------------------------------|-------|---------|--------------------|----------------------------------------------------------------------------|\n",
    "| 1  | [Environment detection](##1-Environment-detection) | 1     | No      | uneditable         | detect whether the notebook are invoked for packaging or in production     |\n",
    "| 2  | [Preparing AIT SDK](##2-Preparing-AIT-SDK)         | 1     | Yes     | uneditable         | download and install AIT SDK                                               |\n",
    "| 3  | [Dependency Management](##3-Dependency-Management) | 3     | Yes     | required(cell #2)  | generate requirements.txt for Docker container                             |\n",
    "| 4  | [Importing Libraries](##4-Importing-Libraries)     | 2     | Yes     | required(cell #1)  | import required libraries                                                  |\n",
    "| 5  | [Manifest Generation](##5-Manifest-Generation)     | 1     | Yes     | required           | generate AIT Manifest                                                      |\n",
    "| 6  | [Prepare for the Input](##6-Prepare-for-the-Input) | 1     | Yes     | required           | generate AIT Input JSON (inventory mapper)                                 |\n",
    "| 7  | [Initialization](##7-Initialization)               | 1     | No      | uneditable         | initialization for AIT execution                                           |\n",
    "| 8  | [Function definitions](##8-Function-definitions)   | N     | No      | required           | define functions invoked from Main area.<br> also define output functions. |\n",
    "| 9  | [Main Algorithms](##9-Main-Algorithms)             | 1     | No      | required           | area for main algorithms of an AIT                                         |\n",
    "| 10 | [Entry point](##10-Entry-point)                    | 1     | No      | uneditable         | an entry point where Qunomon invoke this AIT from here                     |\n",
    "| 11 | [License](##11-License)                            | 1     | Yes     | required           | generate license information                                               |\n",
    "| 12 | [Deployment](##12-Deployment)                      | 1     | Yes     | uneditable         | convert this notebook to the python file for packaging purpose             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## notebook template revision history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "1.0.1 2020/10/21\n",
    "\n",
    "* add revision history\n",
    "* separate `create requirements and pip install` editable and noeditable\n",
    "* separate `import` editable and noeditable\n",
    "\n",
    "1.0.0 2020/10/12\n",
    "\n",
    "* new cerarion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #1 Environment detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Determine whether to start AIT or jupyter by startup argument\n",
    "import sys\n",
    "is_ait_launch = (len(sys.argv) == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #2 Preparing AIT SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "if not is_ait_launch:\n",
    "    # get ait-sdk file name\n",
    "    from pathlib import Path\n",
    "    from glob import glob\n",
    "    import re\n",
    "    import os\n",
    "\n",
    "    current_dir = %pwd\n",
    "\n",
    "    ait_sdk_path = \"./ait_sdk-*-py3-none-any.whl\"\n",
    "    ait_sdk_list = glob(ait_sdk_path)\n",
    "    ait_sdk_name = os.path.basename(ait_sdk_list[-1])\n",
    "\n",
    "    # install ait-sdk\n",
    "    !pip install -q --upgrade pip\n",
    "    !pip install -q --no-deps --force-reinstall ./$ait_sdk_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #3 Dependency Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #3-1 [uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_requirements_generator import AITRequirementsGenerator\n",
    "    requirements_generator = AITRequirementsGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #3-2 [required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    requirements_generator.add_package('pandas', '2.2.3')\n",
    "    requirements_generator.add_package('evaluate', '0.4.3')\n",
    "    requirements_generator.add_package('transformers', '4.46.3')\n",
    "    requirements_generator.add_package('torch', '2.5.1')\n",
    "    requirements_generator.add_package('torchvision', '0.20.1')\n",
    "    requirements_generator.add_package('torchaudio', '2.5.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #3-3 [uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "if not is_ait_launch:\n",
    "    requirements_generator.add_package(f'./{ait_sdk_name}')\n",
    "    requirements_path = requirements_generator.create_requirements(current_dir)\n",
    "\n",
    "    !pip install -q -r $requirements_path "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #4 Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #4-1 [required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #4-2 [uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# must use modules\n",
    "from os import path\n",
    "import shutil  # do not remove\n",
    "from ait_sdk.common.files.ait_input import AITInput  # do not remove\n",
    "from ait_sdk.common.files.ait_output import AITOutput  # do not remove\n",
    "from ait_sdk.common.files.ait_manifest import AITManifest  # do not remove\n",
    "from ait_sdk.develop.ait_path_helper import AITPathHelper  # do not remove\n",
    "from ait_sdk.utils.logging import get_logger, log, get_log_path  # do not remove\n",
    "from ait_sdk.develop.annotation import measures, resources, downloads, ait_main  # do not remove\n",
    "# must use modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #5 Manifest Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_manifest_generator import AITManifestGenerator\n",
    "    manifest_genenerator = AITManifestGenerator(current_dir)\n",
    "    manifest_genenerator.set_ait_name('eval_llm_perplexity_score')\n",
    "    manifest_genenerator.set_ait_description('LLMモデルで問題領域の質問に対して回答し、その生成されたテキストの品質を評価します。LLM評価基準を用いて、回答テキストのPerplexityスコアを計算し、テキストの質を数値化します。')\n",
    "    manifest_genenerator.set_ait_source_repository('https://github.com/aistairc/Qunomon_AIT_eval_llm_perplexity_score')\n",
    "    manifest_genenerator.set_ait_version('1.0')\n",
    "    manifest_genenerator.add_ait_licenses('Apache License Version 2.0')\n",
    "    manifest_genenerator.add_ait_keywords('LLM')\n",
    "    manifest_genenerator.add_ait_keywords('Perplexity')\n",
    "    manifest_genenerator.set_ait_quality('https://ait-hub.pj.aist.go.jp/ait-hub/api/0.0.1/qualityDimensions/機械学習品質マネジメントガイドライン第三版/C-1機械学習モデルの正確性')\n",
    "    inventory_requirement_data = manifest_genenerator.format_ait_inventory_requirement(format_=['json'])\n",
    "    manifest_genenerator.add_ait_inventories(name='question_data', \n",
    "                                              type_='dataset', \n",
    "                                              description='質問と回答のペアを含むデータセット \\nJSON形式{inputs:array, ground_truth:array}\\n例：{inputs: [MLflowとは？], ground_truth: [MLflowは、機械学習ライフサイクルを管理するオープンプラットフォーム]}', \n",
    "                                              requirement=inventory_requirement_data)\n",
    "    inventory_requirement_model = manifest_genenerator.format_ait_inventory_requirement(format_=['ALL'])\n",
    "    manifest_genenerator.add_ait_inventories(name='llm_model_dir', \n",
    "                                              type_='model', \n",
    "                                              description='事前にトレーニング済みの大規模言語モデルと、そのモデルの設定ファイルを保存したディレクトリ\\n 例:T5, GPT-3\\n モデルファイルは、config.json, model.safetensors, generation_config.json, special_tokens_map.json, tokenizer_config.json, tokenizer.jsonを含む', \n",
    "                                              requirement=inventory_requirement_model)\n",
    "    manifest_genenerator.add_ait_measures(name='Perplexity_Score', \n",
    "                                           type_='float', \n",
    "                                           description='計算されたPerplexityスコア', \n",
    "                                           structure='single',\n",
    "                                           min='0')\n",
    "    manifest_genenerator.add_ait_resources(name='sample_data_csv',  \n",
    "                                           type_='table', \n",
    "                                           description='Perplexityスコアが最も低い10セットのデータサンプル')\n",
    "    manifest_genenerator.add_ait_downloads(name='Log', \n",
    "                                            description='AIT実行ログ')\n",
    "    manifest_genenerator.add_ait_downloads(name='eval_result', \n",
    "                                            description='実行結果を示すCSVファイル。以下の項目を含む\\n inputs:モデルに入力されたデータ\\n predictions:モデルが生成した予測結果\\n ground_truth:期待される正解データ\\n Perplexity:Perplexityスコア')\n",
    "    manifest_path = manifest_genenerator.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #6 Prepare for the Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_input_generator import AITInputGenerator\n",
    "    input_generator = AITInputGenerator(manifest_path)\n",
    "    input_generator.add_ait_inventories(name='question_data',\n",
    "                                     value='question_data.json')\n",
    "    input_generator.add_ait_inventories(name='llm_model_dir',\n",
    "                                     value='model')\n",
    "    input_generator.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #7 Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "logger = get_logger()\n",
    "\n",
    "ait_manifest = AITManifest()\n",
    "ait_input = AITInput(ait_manifest)\n",
    "ait_output = AITOutput(ait_manifest)\n",
    "\n",
    "if is_ait_launch:\n",
    "    # launch from AIT\n",
    "    current_dir = path.dirname(path.abspath(__file__))\n",
    "    path_helper = AITPathHelper(argv=sys.argv, ait_input=ait_input, ait_manifest=ait_manifest, entry_point_dir=current_dir)\n",
    "else:\n",
    "    # launch from jupyter notebook\n",
    "    # ait.input.json make in input_dir\n",
    "    input_dir = '/usr/local/qai/mnt/ip/job_args/1/1'\n",
    "    current_dir = %pwd\n",
    "    path_helper = AITPathHelper(argv=['', input_dir], ait_input=ait_input, ait_manifest=ait_manifest, entry_point_dir=current_dir)\n",
    "\n",
    "ait_input.read_json(path_helper.get_input_file_path())\n",
    "ait_manifest.read_json(path_helper.get_manifest_file_path())\n",
    "\n",
    "### do not edit cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #8 Function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@measures(ait_output, 'Perplexity_Score')\n",
    "def output_score(perplexity_score):\n",
    "    return perplexity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@resources(ait_output, path_helper, 'sample_data_csv', 'sample_data_csv.csv')\n",
    "def save_sample_data_csv(df, file_path: str=None) -> None:\n",
    "    df.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@downloads(ait_output, path_helper, 'eval_result', 'eval_result.csv')\n",
    "def eval_result(eval_data, file_path: str=None) -> str:    \n",
    "    eval_data.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@downloads(ait_output, path_helper, 'Log', 'ait.log')\n",
    "def move_log(file_path: str=None) -> str:\n",
    "    shutil.move(get_log_path(), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perplexityスコア計算用関数\n",
    "def calculate_perplexity(input_text, target_text, tokenizer, model, device):\n",
    "    # トークナイズ\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    targets = tokenizer(target_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    \n",
    "    # デバイスに転送\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    targets = {key: val.to(device) for key, val in targets.items()}\n",
    "    \n",
    "    # モデルの出力とロス計算\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=targets[\"input_ids\"])\n",
    "        loss = outputs.loss  # クロスエントロピー損失\n",
    "    perplexity = math.exp(loss.item())  # Perplexity = exp(損失)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #9 Main Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@ait_main(ait_output, path_helper, is_ait_launch)\n",
    "def main() -> None:\n",
    "    # 並列処理の警告を抑制\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "    with open(ait_input.get_inventory_path('question_data'), \"r\") as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    eval_data = pd.DataFrame(json_data)\n",
    "    \n",
    "    # ローカルに保存されたLLMモデルを読み込む\n",
    "    tokenizer_path = ait_input.get_inventory_path('llm_model_dir')\n",
    "    model_path = ait_input.get_inventory_path('llm_model_dir')\n",
    "    \n",
    "    # Transformers を使用してモデルとトークナイザをロード\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "\n",
    "    # パイプラインの作成\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    text2text_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "    # モデルの予測関数\n",
    "    def predict(inputs):\n",
    "        outputs = text2text_pipeline(\n",
    "            inputs,\n",
    "            max_new_tokens=100,\n",
    "            num_beams=5,\n",
    "            temperature=0.7,\n",
    "            truncation=True\n",
    "        )\n",
    "        return outputs[0][\"generated_text\"]\n",
    "\n",
    "    # データに予測結果を追加\n",
    "    eval_data[\"predictions\"] = eval_data[\"inputs\"].apply(predict)\n",
    "\n",
    "    # perplexityを計算してデータに追加\n",
    "    def calculate_row_perplexity(row):\n",
    "        return calculate_perplexity(row[\"inputs\"], row[\"predictions\"], tokenizer, model, device)\n",
    "    \n",
    "    eval_data[\"Perplexity\"] = eval_data.apply(calculate_row_perplexity, axis=1)\n",
    "\n",
    "    # Perplexityの平均値を計算\n",
    "    avg_perplexity = eval_data[\"Perplexity\"].mean()\n",
    "    print(f\"Average Perplexity: {avg_perplexity}\")\n",
    "    output_score(avg_perplexity)\n",
    "    \n",
    "    # Perplexityスコアで昇順にソートし、上位10行を取得\n",
    "    sorted_df = eval_data.sort_values(by=\"Perplexity\", ascending=True).head(10)\n",
    "    save_sample_data_csv(sorted_df)\n",
    "    \n",
    "    # 結果の出力\n",
    "    print(f\"Evaluation results:\\n{eval_data}\")\n",
    "    eval_result(eval_data)\n",
    "    \n",
    "    # AIT実行ログ出力\n",
    "    move_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #10 Entry point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/usr/local/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Perplexity: 4.707290412170403\n",
      "Evaluation results:\n",
      "                                               inputs  \\\n",
      "0                                     What is MLflow?   \n",
      "1                                      What is Spark?   \n",
      "2                  Explain the purpose of Kubernetes.   \n",
      "3          What is the significance of deep learning?   \n",
      "4                How does blockchain technology work?   \n",
      "5               What is the Internet of Things (IoT)?   \n",
      "6           What are the benefits of cloud computing?   \n",
      "7                      Explain the concept of DevOps.   \n",
      "8                             What is edge computing?   \n",
      "9   How does reinforcement learning differ from su...   \n",
      "10                   What is artificial intelligence?   \n",
      "11           Explain the concept of a neural network.   \n",
      "12                               What is a data lake?   \n",
      "13                            What are microservices?   \n",
      "14         What is natural language processing (NLP)?   \n",
      "15  Explain the purpose of continuous integration ...   \n",
      "16                         What is quantum computing?   \n",
      "17                   What are recommendation systems?   \n",
      "18           What is overfitting in machine learning?   \n",
      "19      What is the purpose of hyperparameter tuning?   \n",
      "\n",
      "                                         ground_truth  \\\n",
      "0   MLflow is an open-source platform for managing...   \n",
      "1   Apache Spark is an open-source, distributed co...   \n",
      "2   Kubernetes is an open-source platform designed...   \n",
      "3   Deep learning is a subset of machine learning ...   \n",
      "4   Blockchain is a decentralized and distributed ...   \n",
      "5   The Internet of Things (IoT) refers to the net...   \n",
      "6   Cloud computing allows users to access computi...   \n",
      "7   DevOps is a set of practices that combines sof...   \n",
      "8   Edge computing is a distributed computing para...   \n",
      "9   Reinforcement learning is a machine learning a...   \n",
      "10  Artificial intelligence (AI) refers to the sim...   \n",
      "11  A neural network is a computational model insp...   \n",
      "12  A data lake is a centralized repository that a...   \n",
      "13  Microservices is an architectural style where ...   \n",
      "14  Natural language processing (NLP) is a field o...   \n",
      "15  Continuous integration (CI) is a development p...   \n",
      "16  Quantum computing is a type of computation tha...   \n",
      "17  Recommendation systems are algorithms designed...   \n",
      "18  Overfitting in machine learning occurs when a ...   \n",
      "19  Hyperparameter tuning is the process of optimi...   \n",
      "\n",
      "                                          predictions  Perplexity  \n",
      "0   MLflow?: What is MLflow? What is MLflow? What ...    2.707092  \n",
      "1                       What is Spark? What is Spark?    2.456979  \n",
      "2   . Explain the purpose of Kubernetes. Explain t...    3.032322  \n",
      "3   ? What is the significance of deep learning? W...    3.007082  \n",
      "4   How does blockchain technology work? How does ...    7.248052  \n",
      "5   (IoT)?? (IoT)?? What is the Internet of Things...    4.080784  \n",
      "6   ? What are the benefits of cloud computing? Wh...    5.306556  \n",
      "7   Explain the concept of DevOps. Explain the con...    6.314424  \n",
      "8   computing? What is edge computing? What is edg...    8.086435  \n",
      "9   ? How is reinforcement learning different from...    2.846083  \n",
      "10  ? What is artificial intelligence? What is art...    5.308266  \n",
      "11  concept of neural network. Explain the concept...    6.074628  \n",
      "12  What is a data lake? What is a data lake?? Wha...    4.118320  \n",
      "13  ? What are microservices?? What are microservi...    5.770735  \n",
      "14  (NLP)? What is natural language processing (NL...   10.527246  \n",
      "15  (CI). (CI). Explain the purpose of continuous ...    2.734578  \n",
      "16  is quantum computing? What is quantum computin...    4.661697  \n",
      "17  are recommendation systems? What are recommend...    3.811917  \n",
      "18  ?? What is overfitting in machine learning? Wh...    3.212728  \n",
      "19  tuning? What is the purpose of hyperparameter ...    2.839884  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #11 License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ait_owner='AIST'\n",
    "ait_creation_year='2024'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #12 Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    from ait_sdk.deploy import prepare_deploy\n",
    "    from ait_sdk.license.license_generator import LicenseGenerator\n",
    "    \n",
    "    current_dir = %pwd\n",
    "    prepare_deploy(ait_sdk_name, current_dir, requirements_path)\n",
    "    \n",
    "    # output License.txt\n",
    "    license_generator = LicenseGenerator()\n",
    "    license_generator.write('../top_dir/LICENSE.txt', ait_creation_year, ait_owner)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc00c6a56d87bd8bd7773e730c60ddfdb8804da6b7537df09499efbcf81630f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
